{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Concatenate, Layer, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, Flatten,LeakyReLU,ReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from functools import partial\n",
    "from gumbel_softmax import GumbelSoftmax\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "pd.options.display.max_rows = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining Class\n",
    "## Implement  multi-head attention as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a Transformer block as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Implement a Transformer block as a layer\n",
    "\"\"\"\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Class 3. Implement 1D-Positional encoding and 2D-Locational encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding1D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding1D, self).__init__()\n",
    "        self.channels = channels\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        :param tensor: A 3d tensor of size (batch_size, x, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 3:\n",
    "            raise RuntimeError(\"The input tensor has to be 3d!\")\n",
    "        _, x, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1)\n",
    "        emb = torch.zeros((x,self.channels),device=tensor.device).type(tensor.type())\n",
    "        emb[:,:self.channels] = emb_x\n",
    "\n",
    "        return emb[None,:,:orig_ch]\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        :param channels: The last dimension of the tensor you want to apply pos emb to.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding2D, self).__init__()\n",
    "        channels = int(np.ceil(channels/2))\n",
    "        self.channels = channels\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, channels, 2).float() / channels))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param tensor: A 4d tensor of size (batch_size, x, y, ch)\n",
    "        :return: Positional Encoding Matrix of size (batch_size, x, y, ch)\n",
    "        \"\"\"\n",
    "        if len(tensor.shape) != 4:\n",
    "            raise RuntimeError(\"The input tensor has to be 4d!\")\n",
    "        _, x, y, orig_ch = tensor.shape\n",
    "        pos_x = torch.arange(x, device=tensor.device).type(self.inv_freq.type())\n",
    "        pos_y = torch.arange(y, device=tensor.device).type(self.inv_freq.type())\n",
    "        sin_inp_x = torch.einsum(\"i,j->ij\", pos_x, self.inv_freq)\n",
    "        sin_inp_y = torch.einsum(\"i,j->ij\", pos_y, self.inv_freq)\n",
    "        emb_x = torch.cat((sin_inp_x.sin(), sin_inp_x.cos()), dim=-1).unsqueeze(1)\n",
    "        emb_y = torch.cat((sin_inp_y.sin(), sin_inp_y.cos()), dim=-1)\n",
    "        emb = torch.zeros((x,y,self.channels*2),device=tensor.device).type(tensor.type())\n",
    "        emb[:,:,:self.channels] = emb_x\n",
    "        emb[:,:,self.channels:2*self.channels] = emb_y\n",
    "        return emb[None,:,:,:orig_ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution() ## For implementing WGAN-GP in training process \n",
    "gpu = tf.config.experimental.get_visible_devices('GPU')[0] ## Identify the GPU\n",
    "tf.config.experimental.set_memory_growth(device = gpu, enable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the sample data\n",
    "   * Large-scale incomplete data (Smart card data)\n",
    "       * (Input) Trip-chain attributes (y_train_SC_seq)\n",
    "       * (Input) General attributes (y_train_SC_nseq)\n",
    "   * Small-scale complete data (Travel survey data)\n",
    "       * (Input) Trip-chain attributes (y_train_seq)\n",
    "       * (Input) General attributes (y_train_nseq)\n",
    "       * (Output) Qualitative attributes (x_train_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_SC_seq = np.load('Data/y_train_SC_seq_LatLon.npy',allow_pickle=True)\n",
    "y_test_SC_seq = np.load('Data/y_test_SC_seq_LatLon.npy',allow_pickle=True)\n",
    "y_train_seq = np.load('Data/y_train_seq.npy',allow_pickle=True)\n",
    "y_test_seq = np.load('Data/y_test_seq.npy',allow_pickle=True)\n",
    "\n",
    "y_train_nseq= pd.read_csv('Data/y_train_nseq.csv')\n",
    "y_test_nseq= pd.read_csv('Data/y_test_nseq.csv')\n",
    "y_train_SC_nseq= pd.read_csv('Data/y_train_SC_nseq.csv')\n",
    "y_test_SC_nseq= pd.read_csv('Data/y_test_SC_nseq.csv')\n",
    "x_train_cond= pd.read_csv('Data/x_train_cond.csv')\n",
    "x_test_cond= pd.read_csv('Data/x_test_cond.csv')\n",
    "\n",
    "## Qualitative attrubutes in the raw small-scale complete data\n",
    "x_train_cond_R = pd.read_csv('Data/train_complete_qualitative.csv')\n",
    "y_test_cond_SC_R = pd.read_csv('Data/train_incomplete_tripChain_LatLon.csv')\n",
    "\n",
    "## Extract the LatLon Information\n",
    "y_train_LatLon = y_train_SC_seq[:,:,53:55]\n",
    "y_test_LatLon = y_test_SC_seq[:,:,53:55]\n",
    "y_train_realStay = y_train_SC_seq[:,:,55]\n",
    "y_test_realStay = y_test_SC_seq[:,:,55]\n",
    "\n",
    "y_train_SC_seq = y_train_SC_seq[:,:,:53]\n",
    "y_test_SC_seq = y_test_SC_seq[:,:,:53]\n",
    "\n",
    "for i in range(3):\n",
    "    y_train_SC_seq = np.insert(y_train_SC_seq,49,0,axis=2)\n",
    "    y_test_SC_seq = np.insert(y_test_SC_seq,49,0,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = y_train_seq.shape[2]-4 # The number of input variables including sequential information\n",
    "maxlen = 5  # The number of maximum sequence of trip-chain\n",
    "num_data = y_train_seq.shape[0] # The number of individuals in training data (complete)\n",
    "num_data_SC = y_train_SC_seq.shape[0] # The number of individuals in training data (incomplete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function for 1D-Positional and 2D-Locational encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1D Positional Encoding (numbpy implementation)\n",
    "def seq(data, data_len):\n",
    "    \n",
    "    pos_encoding = PositionalEncoding1D(num_features)\n",
    "    d = torch.zeros((1,maxlen,num_features))\n",
    "    pos_1d_emb = pos_encoding(d) \n",
    "    pos_1d_emb = pos_1d_emb.numpy()\n",
    "    \n",
    "    pos_seq_emb = []\n",
    "    for i in range(data_len):\n",
    "        for j in range(maxlen):\n",
    "            a = int(data[i,j,num_features+3])\n",
    "            if a == 1 :\n",
    "                b = pos_1d_emb[:,0,:]\n",
    "            elif a == 2:\n",
    "                b = pos_1d_emb[:,1,:]\n",
    "            elif a == 3:\n",
    "                b = pos_1d_emb[:,2,:]\n",
    "            elif a == 4:\n",
    "                b = pos_1d_emb[:,3,:]\n",
    "            elif a == 5:\n",
    "                b = pos_1d_emb[:,4,:]\n",
    "            else :\n",
    "                b = np.zeros((1,num_features))\n",
    "            pos_seq_emb.append(b)\n",
    "    pos_seq_emb=np.array(pos_seq_emb)\n",
    "    pos_seq_emb=pos_seq_emb.reshape(data_len,maxlen,num_features)  \n",
    "    \n",
    "    for k in range(4):\n",
    "        data = np.delete(data,num_features, axis=2)\n",
    "    \n",
    "\n",
    "    data_seq = data + pos_seq_emb\n",
    "    \n",
    "    return data_seq\n",
    "\n",
    "## 2D Lositional Encoding (numbpy implementation)\n",
    "def selo(data, data_len):\n",
    "    pos_encoding = PositionalEncoding1D(num_features)\n",
    "    d = torch.zeros((1,maxlen,num_features))\n",
    "    pos_1d_emb = pos_encoding(d) \n",
    "    pos_1d_emb = pos_1d_emb.numpy()\n",
    "    \n",
    "    pos_seq_emb = []    \n",
    "    for i in range(data_len):\n",
    "        for j in range(maxlen):\n",
    "            a = int(data[i,j,num_features+3])\n",
    "            if a == 1 :\n",
    "                b = pos_1d_emb[:,0,:]\n",
    "            elif a == 2:\n",
    "                b = pos_1d_emb[:,1,:]\n",
    "            elif a == 3:\n",
    "                b = pos_1d_emb[:,2,:]\n",
    "            elif a == 4:\n",
    "                b = pos_1d_emb[:,3,:]\n",
    "            elif a == 5:\n",
    "                b = pos_1d_emb[:,4,:]\n",
    "            else :\n",
    "                b = np.zeros((1,num_features))\n",
    "            pos_seq_emb.append(b)\n",
    "    pos_seq_emb=np.array(pos_seq_emb)\n",
    "    pos_seq_emb=pos_seq_emb.reshape(data_len,maxlen,num_features)\n",
    "    \n",
    "    p_enc_2d = PositionalEncoding2D(num_features)\n",
    "    m = torch.zeros((1,95,40,num_features)) # 21 by 21 grids\n",
    "    pos_2d_emb = p_enc_2d(m)\n",
    "    pos_2d_emb = pos_2d_emb.numpy()\n",
    "    pos_2d_emb[:,0,0,:] = 0\n",
    "    \n",
    "    pos_loc_emb = []    \n",
    "    for i in range(data_len):           \n",
    "        a=pos_2d_emb[:,int(data[i,0,num_features]),int(data[i,0,num_features+1]),:]\n",
    "        b=pos_2d_emb[:,int(data[i,1,num_features]),int(data[i,1,num_features+1]),:]\n",
    "        c=pos_2d_emb[:,int(data[i,2,num_features]),int(data[i,2,num_features+1]),:]\n",
    "        d=pos_2d_emb[:,int(data[i,3,num_features]),int(data[i,3,num_features+1]),:]\n",
    "        e=pos_2d_emb[:,int(data[i,4,num_features]),int(data[i,4,num_features+1]),:]\n",
    "        pos_loc_emb.append(a)\n",
    "        pos_loc_emb.append(b)\n",
    "        pos_loc_emb.append(c)\n",
    "        pos_loc_emb.append(d)\n",
    "        pos_loc_emb.append(e)\n",
    "    pos_loc_emb=np.array(pos_loc_emb)\n",
    "    pos_loc_emb=np.reshape(pos_loc_emb, (data_len,maxlen,num_features))\n",
    "    \n",
    "    for k in range(4):\n",
    "        data = np.delete(data,num_features, axis=2)\n",
    "\n",
    "\n",
    "    data_seq_loc = data + pos_seq_emb + pos_loc_emb\n",
    "    \n",
    "    return data_seq_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Applying the positional and locational encoding to the trip-chain attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seq_1d = seq(y_train_seq,len(y_train_seq)) # complete trip-chain attributes with 1D-positional encoding\n",
    "y_train_seq_2d = selo(y_train_seq,len(y_train_seq)) # complete trip-chain attributes with 1D-positional and 2D-locational encoding\n",
    "y_train_SC_seq_1d = seq(y_train_SC_seq,len(y_train_SC_seq)) # incomplete trip-chain attributes with 1D-positional encoding\n",
    "y_train_SC_seq_2d = selo(y_train_SC_seq,len(y_train_SC_seq)) # incomplete trip-chain attributes with 1D-positional and 2D-locational encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build WGAN-GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise = Input(shape=(latent_dim))\n",
    "    label_ns = Input(shape=(nseq_dim))  \n",
    "    label = Input(shape=(maxlen,embed_dim))\n",
    "    \n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(label)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    \n",
    "    k = Flatten()(x)   \n",
    "    \n",
    "    inputs = Concatenate()([noise,label_ns,k])  \n",
    "    \n",
    "    h = Dense(intermediate_dim[0])(inputs)\n",
    "    #h = BatchNormalization()(h) \n",
    "    #h = Dropout(0.1)(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    h = Dense(intermediate_dim[1])(h)\n",
    "    #h = BatchNormalization()(h)\n",
    "    #h = Dropout(0.1)(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    h = Dense(intermediate_dim[2])(h)\n",
    "    #h = BatchNormalization()(h)\n",
    "    #h = Dropout(0.1)(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "   \n",
    "\n",
    "    cat_outputs = [] # Six socioeconomic factors (Qualitative attributes)\n",
    "    for i in ['Home_income', 'Home_car', 'Home_drive', 'Age', 'Gender','Home_type']:\n",
    "        t = Dense(x_train_cond_R[i].nunique())(h)\n",
    "        #t = Activation('softmax')(t) # You can choose the softmax rather than gumbel\n",
    "        t = gumbel(t,6)\n",
    "        cat_outputs.append(t)\n",
    "    \n",
    "    tp_outputs = [] # Trip purposes of each trip in the trip-chain (Qualitative attributes)\n",
    "    p = Dense(48,activation='relu')(x)\n",
    "    p = Dense(24,activation='relu')(p)\n",
    "    p = Dense(12,activation='relu')(p)\n",
    "    for i in range(5):\n",
    "        t = Dense(6)(p[:,i,:])\n",
    "        #t = Activation('softmax')(t) # You can choose the softmax rather than gumbel \n",
    "        t = gumbel(t,6)\n",
    "        cat_outputs.append(t)\n",
    "                                 \n",
    "       \n",
    "    concat = Concatenate()(cat_outputs)\n",
    "    \n",
    "    \n",
    "    model = Model([noise,label_ns,label],concat)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build critic(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_critic():\n",
    "    \n",
    "    img = Input(shape=x_train_cond.shape[1])\n",
    "    label = Input(shape=(maxlen,embed_dim))\n",
    "    label_ns = Input(shape=(nseq_dim))  \n",
    "    \n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(label)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "    x = transformer_block(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    inputs = Concatenate()([img,label_ns,x])  \n",
    "\n",
    "    h = Dense(intermediate_dim[2])(inputs)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    h = Dense(intermediate_dim[1])(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    h = Dense(intermediate_dim[0])(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    validity = Dense(1)(h)\n",
    "    \n",
    "    model = Model(inputs = [img,label_ns,label],outputs = validity)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define functions for WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "def RandomWeightedAverage(inputs):\n",
    "    alpha = K.random_uniform((BATCH_SIZE, 1))\n",
    "    return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyperparameter Setting for Conditional WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting hyperparameters from MultiCATGAN\n",
    "intermediate_dim = [256,256,256]\n",
    "latent_dim = 128\n",
    "optimizer = Adam(lr=2e-04) ## \n",
    "BATCH_SIZE = 256\n",
    "gumbel = GumbelSoftmax(name = 'gumbel')\n",
    "embed_dim = num_features\n",
    "nseq_dim = y_train_nseq.shape[1]\n",
    "num_heads = 4\n",
    "ff_dim = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Conditional WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Build\n",
    "generator = build_generator()\n",
    "critic = build_critic()\n",
    "\n",
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#       for the Critic\n",
    "#-------------------------------\n",
    "\n",
    "## Freeze generator's layers while training critic\n",
    "generator.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "# Image input (real sample)\n",
    "real_img = Input(shape=x_train_cond.shape[1])\n",
    "\n",
    "# Noise input\n",
    "z_disc = Input(shape=(latent_dim))\n",
    "# Generate image based of noise (fake sample) and add label to the input \n",
    "label = Input(shape=(maxlen,embed_dim))\n",
    "label_ns = Input(shape=(nseq_dim))  \n",
    "fake_img = generator([z_disc,label_ns,label])\n",
    "\n",
    "# Discriminator determines validity of the real and fake images\n",
    "fake = critic([fake_img,label_ns,label])\n",
    "valid = critic([real_img,label_ns,label])\n",
    "\n",
    "\n",
    "# Construct weighted average between real and fake images\n",
    "interpolated_img = RandomWeightedAverage([real_img, fake_img])\n",
    "\n",
    "# Determine validity of weighted sample\n",
    "validity_interpolated = critic([interpolated_img,label_ns,label])\n",
    "\n",
    "partial_gp_loss = partial(gradient_penalty_loss,averaged_samples=interpolated_img)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "critic_model = Model(inputs=[real_img,label_ns,label,z_disc], outputs=[valid, fake, validity_interpolated])\n",
    "critic_model.compile(loss=[wasserstein_loss,\n",
    "                           wasserstein_loss,\n",
    "                           partial_gp_loss],\n",
    "                           optimizer=optimizer,\n",
    "                           loss_weights=[1, 1, 10])\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#         for Generator\n",
    "#-------------------------------\n",
    "\n",
    "# For the generator we freeze the critic's layers\n",
    "critic.trainable = False\n",
    "generator.trainable = True\n",
    "\n",
    "# Sampled noise for input to generator\n",
    "z_gen = Input(shape=(latent_dim))\n",
    "# add label to the input\n",
    "label = Input(shape=(maxlen,embed_dim))\n",
    "label_ns = Input(shape=(nseq_dim))  \n",
    "# Generate images based of noise\n",
    "img = generator([z_gen,label_ns,label])\n",
    "\n",
    "# Discriminator determines validity\n",
    "valid = critic([img,label_ns,label])\n",
    "\n",
    "# Defines generator model\n",
    "generator_model = Model([z_gen,label_ns,label], valid)\n",
    "generator_model.compile(loss=wasserstein_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "## Train\n",
    "epochs = 40000 # 1 hours 7000\n",
    "sample_interval = 500\n",
    "n_critic = 5\n",
    "BATCH_SIZE = 256\n",
    "losslog = []\n",
    "\n",
    "# Load the dataset\n",
    "X_train = x_train_cond.values.astype(\"float32\")\n",
    "y_train = y_train_seq_2d\n",
    "y_train_ns = y_train_nseq.values.astype(\"float32\")\n",
    "y_train_SC = y_train_SC_seq_2d\n",
    "y_train_SC_ns = y_train_SC_nseq.values.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Adversarial ground truths\n",
    "valid = - np.ones(BATCH_SIZE)\n",
    "fake =  np.ones(BATCH_SIZE)\n",
    "dummy = np.zeros(BATCH_SIZE) # Dummy gt for gradient penalty\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(n_critic):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random batch of images\n",
    "        \n",
    "        \n",
    "        idx = np.random.randint(0,X_train.shape[0],BATCH_SIZE)\n",
    "        imgs, labels, labels_ns = X_train[idx], y_train[idx], y_train_ns[idx]\n",
    "\n",
    "        # Sample generator input\n",
    "        noise = np.random.normal(0,1,[BATCH_SIZE,latent_dim]) \n",
    "        # Train the critic\n",
    "        d_loss = critic_model.train_on_batch([imgs, labels_ns,labels, noise], [valid, fake, dummy])\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Generator\n",
    "    # ---------------------\n",
    "    idx_SC = np.random.randint(0, y_train_SC.shape[0], BATCH_SIZE)\n",
    "    sampled_labels,sampled_labels_ns = y_train_SC[idx_SC],y_train_SC_ns[idx_SC]\n",
    "    g_loss = generator_model.train_on_batch([noise,sampled_labels_ns,sampled_labels], valid)\n",
    "\n",
    "    # Plot the progress\n",
    "    # Plot the progress\n",
    "\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % sample_interval == 0:\n",
    "        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "        losslog.append([d_loss[0], g_loss])\n",
    "        generator.save_weights('Py_generator/AttnMO_XY_F1', overwrite=True)\n",
    "        critic.save_weights('Py_critic/AttnMO_XY_F1', overwrite=True)\n",
    "        \n",
    "        \n",
    "print(\"time :\", time.time() - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the qualitative attributes using generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for evaluation\n",
    "## Convert the dummy qualitative attributes into categorical one\n",
    "def wide_to_long(samples_pop):\n",
    "    resamples = []\n",
    "    for j in range(samples_pop.shape[0]):\n",
    "        if(type(samples_pop) is np.ndarray):\n",
    "            sam = samples_pop[j]\n",
    "        else:\n",
    "            sam = samples_pop.values[j]\n",
    "        resamples_row = []\n",
    "        for i in range(len(n_uni_col)-1):\n",
    "            idx = range(n_uni_col[i],n_uni_col[i+1])\n",
    "            resamples_row = np.append(resamples_row,np.random.choice(col_pop[idx],p=sam[idx],size=1))\n",
    "        resamples = np.concatenate((resamples,resamples_row),axis=0)\n",
    "    resamples = resamples.reshape(samples_pop.shape[0],len(n_uni_col)-1 )\n",
    "    resamples = pd.DataFrame(resamples,columns= x_train_cond_R.columns[1:7].to_list()+[\"TP_0\",\"TP_1\",\"TP_2\",\"TP_3\",\"TP_4\"])\n",
    "    resamples = resamples.apply(lambda x: x.astype('category'))\n",
    "    return(resamples)\n",
    "\n",
    "## Calculate the mean Jenson-Shannon Distance\n",
    "def mean_JSD(samples,resamples):\n",
    "    Marg_JSD = []\n",
    "    for col in samples.columns:\n",
    "        resam = pd.value_counts(resamples[col]).sort_index()\n",
    "        sam = pd.value_counts(samples[col]).sort_index()\n",
    "        tab = pd.merge(resam,sam,left_index=True, right_index=True,how='outer')\n",
    "        tab = tab.fillna(0)\n",
    "        Marg_JSD.append(jensenshannon(tab.iloc[:,0], tab.iloc[:,1]))\n",
    "     \n",
    "\n",
    "    bi_index = combinations(samples.columns,2)\n",
    "    bi_index = list(bi_index)\n",
    "    col1,col2 = bi_index[0]\n",
    "\n",
    "    Bi_JSD = []\n",
    "    for col1,col2 in bi_index:\n",
    "        resam = pd.DataFrame(pd.crosstab(resamples[col1],resamples[col2],rownames=[col1],colnames=[col2]).stack().sort_index())\n",
    "        sam = pd.DataFrame(pd.crosstab(samples[col1],samples[col2],rownames=[col1],colnames=[col2]).stack().sort_index())\n",
    "        tab = pd.merge(resam,sam,left_index=True, right_index=True,how='outer')\n",
    "        tab = tab.fillna(0)\n",
    "        Bi_JSD.append(jensenshannon(tab.iloc[:,0], tab.iloc[:,1]))\n",
    "\n",
    "    return([Marg_JSD,Bi_JSD])\n",
    "\n",
    "# ## Calculate the mean Jenson-Shannon Distanc\n",
    "\n",
    "# def get_resamples(y_test_SC_seq,y_test_SC_nseq_ns,num_gen=1):\n",
    "#     resamples_SC = pd.DataFrame()\n",
    "#     for i in range(num_gen):\n",
    "#         y_test_SC = selo(y_test_SC_seq,len(y_test_SC_seq))\n",
    "#         y_test_SC_ns = y_test_SC_nseq.values.astype(\"float32\")\n",
    "#         idx = sample(range(y_test_SC.shape[0]),x_test_cond.shape[0])\n",
    "#         samples_act = y_test_SC[idx,:]\n",
    "#         samples_act_ns = y_test_SC_ns[idx,:]\n",
    "#         samples_pop_SC = generate_images(samples_act,samples_act_ns)\n",
    "#         resamples_SC = pd.concat([resamples_SC,wide_to_long(samples_pop_SC)],axis=0)\n",
    "#     return(resamples_SC)\n",
    "\n",
    "# Define the generator function\n",
    "def generate_images(label,label_ns):\n",
    "    generator.load_weights('Py_generator/AttnMO_XY_F1')\n",
    "    noise = np.random.normal(0, 1, (label.shape[0],latent_dim))\n",
    "    gen_imgs = generator.predict([noise,label_ns,label])\n",
    "   \n",
    "    \n",
    "    return gen_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euijin\\Anaconda3\\envs\\C8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "# Generate the qualitative attributes of smart card\n",
    "y_test_SC = selo(y_test_SC_seq,len(y_test_SC_seq))\n",
    "y_test_SC_ns = y_test_SC_nseq.values.astype(\"float32\")\n",
    "\n",
    "samples_act = y_test_SC\n",
    "samples_act_ns = y_test_SC_ns\n",
    "samples_pop_SC = generate_images(samples_act,samples_act_ns)\n",
    "\n",
    "\n",
    "\n",
    "# Generate the qualitative attributes of travel survey (For validation)\n",
    "y_test_TS = selo(y_test_seq,len(y_test_seq))\n",
    "y_test_TS_ns = y_test_nseq.values.astype(\"float32\")\n",
    "idx = sample(range(y_test_TS.shape[0]),x_test_cond.shape[0])\n",
    "\n",
    "samples_act = y_test_TS[idx,:]\n",
    "samples_act_ns = y_test_TS_ns[idx,:]\n",
    "samples_pop = generate_images(samples_act,samples_act_ns)\n",
    "\n",
    "\n",
    "\n",
    "## Make Ground Truth & Test\n",
    "n_uni_col = [x_train_cond_R[i].nunique() for i in x_train_cond_R.columns[1:7]]\n",
    "n_uni_col = [0]+n_uni_col+[6,6,6,6,6]\n",
    "n_uni_col = np.cumsum(n_uni_col)\n",
    "col_pop = x_test_cond.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = wide_to_long(x_test_cond)\n",
    "resamples = wide_to_long(samples_pop)\n",
    "resamples_SC = wide_to_long(samples_pop_SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Construct the genearted data for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-040e3b6b508f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mTripPurposes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresamples_SC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mTripPurposes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTripPurposes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTripPurposes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mLat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test_realStay\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mArrivalTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_SC_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mArrivalTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mArrivalTime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "## Load the Coordinate data for the columne \"P_Arrival_code\" in the trip-chain data\n",
    "## LU1: Ratio of Residential area; LU2: Ratio of Commericial area; LU3: Ratio of other area\n",
    "## P_Arrival_code is TAZ spatial unit in Korea (~1 km radius)\n",
    "TAZ_Coord = pd.read_csv('Data/TAZ_Coord.csv')\n",
    "\n",
    "\n",
    "\n",
    "## Convert the Target attributes from the wide-form to long-form\n",
    "TripPurposes = np.array(resamples_SC.iloc[:,6:11]).reshape((-1,1))\n",
    "TripPurposes = np.array([TripPurposes[x][0][-1] for x in range(TripPurposes.shape[0])]).reshape((-1,1))\n",
    "ActivityDuration = y_test_realStay.reshape((-1,1))\n",
    "ArrivalTime = np.array(y_test_SC_seq[:,:,2:21]).reshape((-1,19))\n",
    "ArrivalTime = np.argmax(ArrivalTime,axis=1).reshape((-1,1))\n",
    "Lat = y_test_LatLon[:,:,0].reshape((-1,1))\n",
    "Lon = y_test_LatLon[:,:,1].reshape((-1,1))\n",
    "df = pd.DataFrame(np.concatenate([Lat,Lon,TripPurposes,ActivityDuration,ArrivalTime],axis=1),\n",
    "                 columns=['Lat','Lon','TripPurposes','ActivityDuration','ArrivalTime'])\n",
    "\n",
    "\n",
    "## Remove the dummy trips (Trip purposes = 'Z' (None))\n",
    "df = df[df['TripPurposes']!='Z']\n",
    "\n",
    "## Assign the value for the attributes\n",
    "df['ArrivalTime'] = df['ArrivalTime'].astype('int')+5 # 5 ~ 23\n",
    "df['TripPurposes'] = df['TripPurposes'].replace(\"0\",\"Commute\")\n",
    "df['TripPurposes'] = df['TripPurposes'].replace(\"1\",\"Work\")\n",
    "df['TripPurposes'] = df['TripPurposes'].replace(\"2\",\"OrganizedHobby\")\n",
    "df['TripPurposes'] = df['TripPurposes'].replace(\"3\",\"Entertainment\")\n",
    "df['TripPurposes'] = df['TripPurposes'].replace(\"4\",\"ReturningHome\")\n",
    "\n",
    "\n",
    "# ## Matching the Grid ID with Lat and Lon\n",
    "# Grid = y_test_cond_SC_R[['P_Arrival_code','P_Arrival_x','P_Arrival_y']]\n",
    "# Grid = Grid.drop_duplicates(subset='P_Arrival_code')\n",
    "# Grid['Gu_code'] = Grid['P_Arrival_code'].astype(\"str\").str[:4]\n",
    "# Grid['P_Arrival_x'] = Grid['P_Arrival_x'].astype('object')\n",
    "# Grid['P_Arrival_y'] = Grid['P_Arrival_y'].astype('object')\n",
    "# Grid = pd.merge(left=TAZ_Coord,right=Grid,how='inner',on='P_Arrival_code')\n",
    "\n",
    "# df = pd.merge(left=df,right=Grid,how='inner',on=['P_Arrival_x','P_Arrival_y'])\n",
    "# df_F = df[['Lon','Lat','ArrivalTime','TripPurposes','ActivityDuration','P_Arr_LU1','P_Arr_LU2','P_Arr_LU3']]\n",
    "\n",
    "## Save the processed data\n",
    "df.to_csv(\"Data/ActivityPattern.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
